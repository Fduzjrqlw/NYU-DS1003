{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhangjunrui/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import logging\n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading the dataset...\n"
     ]
    }
   ],
   "source": [
    "#读入数据集\n",
    "print ('loading the dataset...')\n",
    "df = pd.read_csv('hw1-data.csv' , delimiter = ',')\n",
    "X = df.values[:,:-1]\n",
    "y = df.values[: ,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split into Train and Test...\n"
     ]
    }
   ],
   "source": [
    "#划分训练集和测试集\n",
    "print ('Split into Train and Test...')\n",
    "# train_test_split 参数介绍 \n",
    "## train_test_split(train_data , test_data , test_size , random_state) \n",
    "## 其中test_size可选择正整数或者是[0,1]中的浮点数,表示测试集大小\n",
    "## random_state为随机数种子编号，方便调试\n",
    "X_train , X_test , y_train , y_test = train_test_split(X , y , test_size = 100 , random_state = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_normalization(train , test) : \n",
    "    '''\n",
    "    将每一维特征的数据利用线性变换[0,1]对训练数据和测试数据归一化,其中统计量来自于训练数据.\n",
    "    Args:\n",
    "        train - training set , 二维numpy数组(num_instances , num_features)\n",
    "        test - test set , 二维numpy数组(num_instances , num_features)\n",
    "    \n",
    "    Returns:\n",
    "        train_normalized - training set after normalization \n",
    "        test_normalized - test set after normalization\n",
    "    '''\n",
    "    mean = np.mean(train , axis = 0)\n",
    "    std = np.std(train , axis = 0)\n",
    "    try :\n",
    "        Max = np.max(train , axis = 0)\n",
    "        Min = np.min(train , axis = 0)\n",
    "        #这个地方的减法运用了广播机制,考虑后缘维度(从末尾开始算起的维度)的轴长度相同,或者其中的一方长度为1.\n",
    "        train_normalized = (train - Min) / (Max - Min)\n",
    "        test_normalized = (test - Min) / (Max - Min)\n",
    "    except ValueError :\n",
    "        print ('There maybe some features are exactly same !')\n",
    "    return train_normalized , test_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling all to [0,1]\n"
     ]
    }
   ],
   "source": [
    "#归一化\n",
    "print ('Scaling all to [0,1]')\n",
    "X_train , X_test = feature_normalization(X_train , X_test)\n",
    "#添加偏置项 Add bias term\n",
    "## np.hstack函数用来横向堆叠   np.hstack([arr1 , arr2])   要求arr1和arr2都是相同维数的矩阵,比如二维矩阵.然后其中行数要相同\n",
    "## np.vstack函数用来纵向堆叠\n",
    "X_train = np.hstack((X_train , np.ones([X_train.shape[0] , 1])))\n",
    "X_test = np.hstack((X_test , np.ones([X_test.shape[0] , 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_square_loss(X , y , theta) :\n",
    "    '''\n",
    "    给定X,y,theta,计算用X*theta作为y预测的平方损失\n",
    "    Args:\n",
    "        X - 输入特征数据 , 二维numpy数组(num_instances , num_features)\n",
    "        y - 标签label数据 , 一维numpy数组(num_instances)\n",
    "        theta - 模型参数数据 , 一维numpy数组(num_features)\n",
    "    Returns:\n",
    "        loss - 平方损失 , 标量\n",
    "    '''\n",
    "    #这里用到了np.matmul的一些性质 y_ = X * theta.T\n",
    "    #np.matmul(X,theta) = np.matmul(X,theta.T)\n",
    "    y_ = np.matmul(X , theta)\n",
    "    loss = np.mean((y_ - y) * (y_ - y))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_square_loss_gradient(X , y , theta) :\n",
    "    ''' \n",
    "    计算平方损失函数关于参数theta的梯度\n",
    "    Args:\n",
    "        X - 输入特征数据 , 二维numpy数组(num_instances , num_features)\n",
    "        y - 标签label数据 , 一维numpy数组(num_instances)\n",
    "        theta - 模型参数数据 , 一维numpy数组(num_features)\n",
    "    Returns:\n",
    "        grad - 梯度向量 , 一维numpy数组(num_features)\n",
    "    '''\n",
    "    grad = np.matmul(X.T  , np.matmul(X , theta) - y)\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2607.01320543, 2558.32650202, 2505.05425816, 2474.08147112,\n",
       "       2424.54686361, 2379.89122572, 2290.86331386, 2290.86331386,\n",
       "       2190.02613459, 2005.69048982, 1836.4166322 , 1730.17451019,\n",
       "       1450.02761001, 1245.80012271,  821.04028085,  734.55607357,\n",
       "        524.34057467,   90.77052471, 2314.7420968 , 2314.7420968 ,\n",
       "       2314.7420968 , 2148.83249081, 2148.83249081, 2148.83249081,\n",
       "       1989.72414034, 1989.72414034, 1989.72414034, 1915.89546722,\n",
       "       1915.89546722, 1915.89546722, 1874.89861947, 1874.89861947,\n",
       "       1874.89861947, 1185.22961119, 1185.22961119, 1185.22961119,\n",
       "       1439.88546708, 1439.88546708, 1439.88546708, 1583.93020895,\n",
       "       1583.93020895, 1583.93020895, 1649.35361683, 1649.35361683,\n",
       "       1649.35361683, 1685.25585253, 1685.25585253, 1685.25585253,\n",
       "       2623.76814349])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta = np.ones(X_train.shape[1])\n",
    "compute_square_loss(X_train , y_train , theta)\n",
    "compute_square_loss_gradient(X_train , y_train , theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14 32]\n",
      "[14 32]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[1,2,3],[4,5,6]])\n",
    "w = np.array([1,2,3])\n",
    "print (np.matmul(X , w))\n",
    "print (np.matmul(X , w.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
